Federated learning trains a shared model across many clients
without sharing raw data. Each client optimizes a local ob-
jective on private examples and a server aggregates model
updates into a global state. This reduces central ex-
posure of sensitive data and enables training across data
silos with limited connectivity and varied devices, but it
also introduces failures that are uncommon in centralized
training
